# SafeCity Analytics: LA Crime Data (Phase 1)

## Course + Assignment Header
- **Subject Code:** EAS 587  
- **Course:** Data-Intensive Computing (Spring 2026)  
- **Assignment No.:** Assignment 1 (Project Phase 1)  
- **Project Title:** SafeCity Analytics: LA Crime Data Analysis  
- **Instructor:** `<<ADD INSTRUCTOR NAME>>`  
- **Team Members:**  
  - Harsh Mahesh Tikone  
  - Dev Desai  
  - Shwetangi  

---

## 1) Project Overview
This project implements the Phase 1 pipeline for structured crime data analysis using Python:
- Data ingestion check
- Reproducible data cleaning/processing
- Exploratory Data Analysis (EDA) with tables + visualizations

Primary dataset used:
- **Source:** [Crime Data from 2020 to Present (data.gov)](https://catalog.data.gov/dataset/crime-data-from-2020-to-present)
- **File in repo:** `data/raw/crime_data_2024_to_present.csv`
- **Scale:** ~62K rows (meets 50,000+ row requirement)

The code is designed to run from a **fresh local Python environment** and generate all processed outputs in `data/processed/`.

---

## 2) Repository Structure
```text
DIC_Assignment_safecity-analytics/
├── README.md
├── requirements.txt
├── data/
│   ├── raw/
│   │   └── crime_data_2024_to_present.csv
│   └── processed/
│       ├── crime_data_cleaned.csv                # generated by cleaning script
│       ├── data_cleaning_summary.json            # generated by cleaning script
│       └── eda/                                  # generated by EDA script
│           ├── eda_summary.json
│           ├── eda_key_findings.txt
│           ├── tables/
│           └── plots/
└── src/
    ├── data_collection.py
    ├── data_cleaning.py
    └── eda.py
```

---

## 3) Fresh Environment Setup (Reproducible)

### Prerequisites
- Python **3.10+** (tested with Python 3.11)
- `pip`

### Setup Commands (macOS/Linux)
Run from repository root:

```bash
python3 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt
```

### Setup Commands (Windows PowerShell)
```powershell
py -m venv .venv
.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements.txt
```

---

## 4) How to Run (End-to-End)
Run from repository root in this order:

```bash
python src/data_collection.py
python src/data_cleaning.py
python src/eda.py
```

### What each script does
1. `src/data_collection.py`
   - Verifies raw CSV exists
   - Prints row/column count and sample preview

2. `src/data_cleaning.py`
   - Runs full cleaning pipeline (15 operations)
   - Outputs:
     - `data/processed/crime_data_cleaned.csv`
     - `data/processed/data_cleaning_summary.json`

3. `src/eda.py`
   - Runs comprehensive EDA (14 operations)
   - Outputs:
     - `data/processed/eda/tables/*.csv`
     - `data/processed/eda/plots/*.png`
     - `data/processed/eda/eda_summary.json`
     - `data/processed/eda/eda_key_findings.txt`

---

## 5) Reproduction Time (Target: under 10 minutes)
On a normal laptop, from fresh environment:
- Environment + dependency install: ~2 to 4 minutes
- Data inspection + cleaning + EDA execution: ~2 to 5 minutes
- **Total typical time:** ~4 to 9 minutes

Note:
- First matplotlib run may spend extra time creating font cache once.

---

## 6) Key Generated Deliverables for Grading
After successful run, verify these exist:

- Cleaning outputs:
  - `data/processed/crime_data_cleaned.csv`
  - `data/processed/data_cleaning_summary.json`

- EDA summary outputs:
  - `data/processed/eda/eda_summary.json`
  - `data/processed/eda/eda_key_findings.txt`

- EDA tables:
  - `data/processed/eda/tables/01_dataset_profile.csv`
  - `data/processed/eda/tables/02_missingness_by_column.csv`
  - `data/processed/eda/tables/03_numeric_descriptive_stats.csv`
  - `data/processed/eda/tables/04_top20_crime_types.csv`
  - `data/processed/eda/tables/05_top20_areas.csv`
  - `data/processed/eda/tables/06_monthly_trend.csv`
  - `data/processed/eda/tables/07_day_of_week_distribution.csv`
  - `data/processed/eda/tables/08_hour_of_day_distribution.csv`
  - `data/processed/eda/tables/09_victim_age_summary.csv`
  - `data/processed/eda/tables/09_victim_age_groups.csv`
  - `data/processed/eda/tables/10_victim_sex_distribution.csv`
  - `data/processed/eda/tables/11_weapon_usage_top20.csv`
  - `data/processed/eda/tables/12_report_delay_summary.csv`
  - `data/processed/eda/tables/13_case_status_distribution.csv`

- EDA plots:
  - `data/processed/eda/plots/02_missingness_top15.png`
  - `data/processed/eda/plots/04_top20_crime_types.png`
  - `data/processed/eda/plots/05_top20_areas.png`
  - `data/processed/eda/plots/06_monthly_trend.png`
  - `data/processed/eda/plots/07_day_of_week_distribution.png`
  - `data/processed/eda/plots/08_hour_of_day_distribution.png`
  - `data/processed/eda/plots/09_victim_age_distribution.png`
  - `data/processed/eda/plots/10_victim_sex_distribution.png`
  - `data/processed/eda/plots/11_weapon_usage_top20.png`
  - `data/processed/eda/plots/12_report_delay_distribution.png`
  - `data/processed/eda/plots/13_case_status_distribution.png`
  - `data/processed/eda/plots/14_geospatial_hotspots_hexbin.png`

---

## 7) Troubleshooting
- If script says a file is missing:
  - Ensure raw file is exactly:
    - `data/raw/crime_data_2024_to_present.csv`
- If a package import fails:
  - Re-activate virtual environment
  - Re-run: `pip install -r requirements.txt`
- If plotting is slow on first run:
  - This is typically first-time matplotlib font-cache setup.

---

## 8) Notes
- All scripts are standard Python scripts runnable locally.
- Outputs are deterministic and written under `data/processed/`.
- This README is written to allow a grader to reproduce results quickly in a fresh environment.
